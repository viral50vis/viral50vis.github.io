{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/site-packages (0.0)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/site-packages (from sklearn) (0.22.2.post1)\nRequirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.4.1)\nRequirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.18.1)\nRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/site-packages (from scikit-learn->sklearn) (0.14.1)\nRequirement already satisfied: pycountry-convert in /usr/local/lib/python3.7/site-packages (0.7.2)\nRequirement already satisfied: pytest-mock>=1.6.3 in /usr/local/lib/python3.7/site-packages (from pycountry-convert) (2.0.0)\nRequirement already satisfied: repoze.lru>=0.7 in /usr/local/lib/python3.7/site-packages (from pycountry-convert) (0.7)\nRequirement already satisfied: pycountry>=16.11.27.1 in /usr/local/lib/python3.7/site-packages (from pycountry-convert) (19.8.18)\nRequirement already satisfied: pytest>=3.4.0 in /usr/local/lib/python3.7/site-packages (from pycountry-convert) (5.3.5)\nRequirement already satisfied: pytest-cov>=2.5.1 in /usr/local/lib/python3.7/site-packages (from pycountry-convert) (2.8.1)\nRequirement already satisfied: wheel>=0.30.0 in /Users/erik/Library/Python/3.7/lib/python/site-packages (from pycountry-convert) (0.32.3)\nRequirement already satisfied: pprintpp>=0.3.0 in /usr/local/lib/python3.7/site-packages (from pycountry-convert) (0.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.7/site-packages (from pytest>=3.4.0->pycountry-convert) (20.3)\nRequirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/site-packages (from pytest>=3.4.0->pycountry-convert) (8.2.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.7/site-packages (from pytest>=3.4.0->pycountry-convert) (0.1.8)\nRequirement already satisfied: pluggy<1.0,>=0.12 in /usr/local/lib/python3.7/site-packages (from pytest>=3.4.0->pycountry-convert) (0.13.1)\nRequirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/site-packages (from pytest>=3.4.0->pycountry-convert) (19.3.0)\nRequirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.7/site-packages (from pytest>=3.4.0->pycountry-convert) (1.5.0)\nRequirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/site-packages (from pytest>=3.4.0->pycountry-convert) (1.8.1)\nRequirement already satisfied: coverage>=4.4 in /usr/local/lib/python3.7/site-packages (from pytest-cov>=2.5.1->pycountry-convert) (5.0.3)\nRequirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from packaging->pytest>=3.4.0->pycountry-convert) (1.11.0)\nRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/site-packages (from packaging->pytest>=3.4.0->pycountry-convert) (2.4.6)\nRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/site-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=3.4.0->pycountry-convert) (3.1.0)\n"
    }
   ],
   "source": [
    "!pip3 install sklearn\n",
    "!pip3 install pycountry-convert\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import pycountry_convert as pc\n",
    "import json\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [\n",
    "    '2020-01-23',\n",
    "    '2020-01-16',\n",
    "    '2020-01-09',\n",
    "    '2020-01-02',\n",
    "    '2019-12-26',\n",
    "    '2019-12-19',\n",
    "    '2019-12-12',\n",
    "    '2019-12-05',\n",
    "    '2019-11-28',\n",
    "    '2019-11-21',\n",
    "    '2019-11-14',\n",
    "    '2019-11-07',\n",
    "    '2019-10-31',\n",
    "    '2019-10-24',\n",
    "    '2019-10-17',\n",
    "    '2019-10-10',\n",
    "    '2019-10-03',\n",
    "    '2019-09-26',\n",
    "    '2019-09-19',\n",
    "    '2019-09-12',\n",
    "    '2019-09-05',\n",
    "    '2019-08-29',\n",
    "    '2019-08-22',\n",
    "    '2019-08-15',\n",
    "    '2019-08-08',\n",
    "    '2019-08-01',\n",
    "    '2019-07-25',\n",
    "    '2019-07-18',\n",
    "    '2019-07-11',\n",
    "    '2019-07-04',\n",
    "    '2019-06-27',\n",
    "    '2019-06-20',\n",
    "    '2019-06-13',\n",
    "    '2019-06-06',\n",
    "    '2019-05-30',\n",
    "    '2019-05-23',\n",
    "    '2019-05-16',\n",
    "    '2019-05-09',\n",
    "    '2019-05-02',\n",
    "    '2019-04-25',\n",
    "    '2019-04-18',\n",
    "    '2019-04-11',\n",
    "    '2019-04-04',\n",
    "    '2019-03-28',\n",
    "    '2019-03-21',\n",
    "    '2019-03-14',\n",
    "    '2019-03-07',\n",
    "    '2019-02-28',\n",
    "    '2019-02-21',\n",
    "    '2019-02-14',\n",
    "    '2019-02-07',\n",
    "    '2019-01-31',\n",
    "    '2019-01-24',\n",
    "    '2019-01-17',\n",
    "    '2019-01-10',\n",
    "    '2019-01-03',\n",
    "    '2018-12-27',\n",
    "    '2018-12-20',\n",
    "    '2018-12-13',\n",
    "    '2018-12-06',\n",
    "    '2018-11-29',\n",
    "    '2018-11-22',\n",
    "    '2018-11-15',\n",
    "    '2018-11-08',\n",
    "    '2018-11-01',\n",
    "    '2018-10-25',\n",
    "    '2018-10-18',\n",
    "    '2018-10-11',\n",
    "    '2018-10-04',\n",
    "    '2018-09-27',\n",
    "    '2018-09-20',\n",
    "    '2018-09-13',\n",
    "    '2018-09-06',\n",
    "    '2018-08-30',\n",
    "    '2018-08-23',\n",
    "    '2018-08-09',\n",
    "    '2018-08-02',\n",
    "    '2018-07-26',\n",
    "    '2018-07-19',\n",
    "    '2018-07-12',\n",
    "    '2018-07-05',\n",
    "    '2018-06-28',\n",
    "    '2018-06-21',\n",
    "    '2018-06-14',\n",
    "    '2018-06-07',\n",
    "    '2018-05-31',\n",
    "    '2018-05-24',\n",
    "    '2018-05-17',\n",
    "    '2018-05-10',\n",
    "    '2018-05-03',\n",
    "    '2018-04-26',\n",
    "    '2018-04-19',\n",
    "    '2018-04-12',\n",
    "    '2018-04-05',\n",
    "    '2018-03-29',\n",
    "    '2018-03-22',\n",
    "    '2018-03-15',\n",
    "    '2018-03-08',\n",
    "    '2018-03-01',\n",
    "    '2018-02-22',\n",
    "    '2018-02-15',\n",
    "    '2018-02-08',\n",
    "    '2018-02-01',\n",
    "    '2018-01-25',\n",
    "    '2018-01-18',\n",
    "    '2018-01-11',\n",
    "    '2018-01-04',\n",
    "    '2017-12-28',\n",
    "    '2017-12-21',\n",
    "    '2017-12-14',\n",
    "    '2017-12-07',\n",
    "    '2017-11-30',\n",
    "    '2017-11-23',\n",
    "    '2017-11-16',\n",
    "    '2017-11-09',\n",
    "    '2017-11-02',\n",
    "    '2017-10-26',\n",
    "    '2017-10-19',\n",
    "    '2017-10-12',\n",
    "    '2017-10-05',\n",
    "    '2017-09-28',\n",
    "    '2017-09-21',\n",
    "    '2017-09-14',\n",
    "    '2017-09-07',\n",
    "    '2017-08-31',\n",
    "    '2017-08-24',\n",
    "    '2017-08-17',\n",
    "    '2017-08-10',\n",
    "    '2017-08-03',\n",
    "    '2017-07-27',\n",
    "    '2017-07-20',\n",
    "    '2017-07-13',\n",
    "    '2017-07-06',\n",
    "    '2017-06-29',\n",
    "    '2017-06-22',\n",
    "    '2017-06-15',\n",
    "    '2017-06-08',\n",
    "    '2017-05-11',\n",
    "    '2017-05-04',\n",
    "    '2017-04-27',\n",
    "    '2017-04-20',\n",
    "    '2017-04-13',\n",
    "    '2017-04-06',\n",
    "    '2017-03-30',\n",
    "    '2017-03-23',\n",
    "    '2017-03-16',\n",
    "    '2017-03-09',\n",
    "    '2017-03-02',\n",
    "    '2017-02-23',\n",
    "    '2017-02-16',\n",
    "    '2017-02-09',\n",
    "    '2017-02-02',\n",
    "    '2017-01-26',\n",
    "    '2017-01-19',\n",
    "    '2017-01-12',\n",
    "    '2017-01-05'\n",
    "]\n",
    "\n",
    "CCs = [\n",
    "    'POL',\n",
    "    'HND',\n",
    "    'SWE',\n",
    "    'NOR',\n",
    "    'LUX',\n",
    "    'BRA',\n",
    "    'FRA',\n",
    "    'ECU',\n",
    "    'GTM',\n",
    "    'BEL',\n",
    "    'TUR',\n",
    "    'NLD',\n",
    "    'MYS',\n",
    "    'IDN',\n",
    "    'EST',\n",
    "    'ESP',\n",
    "    'CZE',\n",
    "    'CRI',\n",
    "    'VNM',\n",
    "    'AUS',\n",
    "    'LVA',\n",
    "    'GBR',\n",
    "    'DEU',\n",
    "    'URY',\n",
    "    'SVK',\n",
    "    'ARG',\n",
    "    'TWN',\n",
    "    'USA',\n",
    "    'PRT',\n",
    "    'IRL',\n",
    "    'DOM',\n",
    "    'CHE',\n",
    "    'LTU',\n",
    "    'JPN',\n",
    "    'BOL',\n",
    "    'NIC',\n",
    "    'COL',\n",
    "    'HUN',\n",
    "    'MEX',\n",
    "    'MCO',\n",
    "    'BGR',\n",
    "    'ROU',\n",
    "    'ZAF',\n",
    "    'IND',\n",
    "    'ITA',\n",
    "    'DNK',\n",
    "    'PAN',\n",
    "    'PHL',\n",
    "    'NZL',\n",
    "    'PER',\n",
    "    'THA',\n",
    "    'AUT',\n",
    "    'FIN',\n",
    "    'GRC',\n",
    "    'SLV',\n",
    "    'GLO',\n",
    "    'ISR',\n",
    "    'CHL',\n",
    "    'CAN',\n",
    "    'ISL',\n",
    "    'PRY',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '../data/countries/'\n",
    "week_mean_dir = '../data/week_mean/'\n",
    "song_masterlist = '../data/song_masterlist.csv'\n",
    "song_masterlist_norm = '../data/song_masterlist_normalized.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing some values of the song masterlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_ml_df = pd.read_csv(song_masterlist)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "song_ml_df[['danceability', 'energy', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence']] = min_max_scaler.fit_transform(song_ml_df[['danceability', 'energy', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence']])\n",
    "song_ml_df.to_csv(\"../data/song_masterlist_normalized.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating weekly mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Removing .DS_Store\nRemoving .DS_Store\n"
    }
   ],
   "source": [
    "songs_norm = pd.read_csv(song_masterlist_norm)\n",
    "\n",
    "dataframe_collection = {}\n",
    "\n",
    "for date in dates:\n",
    "    dataframe_collection[date] = pd.DataFrame()\n",
    "\n",
    "for directory in os.listdir(base_dir):\n",
    "    path = base_dir + directory + '/'\n",
    "    try:\n",
    "        for filename in os.listdir(path):\n",
    "            try:\n",
    "                current_week = filename.replace('.','_').split('_')[1]\n",
    "                week_df = pd.read_csv(path + filename)\n",
    "\n",
    "                try:\n",
    "                    CC = pc.country_name_to_country_alpha3(directory, cn_name_format=\"default\")\n",
    "                except:\n",
    "                    CC = \"GLO\"\n",
    "                if CC == \"CYP\":\n",
    "                    raise\n",
    "                mean_values = songs_norm.iloc[week_df[\"Song_Index\"]].describe().transpose()[\"mean\"].to_frame().transpose()\n",
    "                mean_values.insert(1, \"CC\", CC)\n",
    "                mean_values = mean_values.set_index(\"CC\")\n",
    "                dataframe_collection[current_week] = dataframe_collection[current_week].append(mean_values)\n",
    "            except:\n",
    "                print(\"Removing \" + filename)\n",
    "                shutil.rmtree(path + filename, ignore_errors=True)\n",
    "    except:\n",
    "        print(\"Removing \" + directory)\n",
    "        shutil.rmtree(path, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimums = dataframe_collection['2017-01-12'].min()\n",
    "maximums = dataframe_collection['2017-01-12'].max()\n",
    "for date in dates:\n",
    "    min_new = dataframe_collection[date].min()\n",
    "    max_new = dataframe_collection[date].max()\n",
    "    minimums = minimums.combine(min_new, min)\n",
    "    maximums = maximums.combine(max_new, max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_json = {}\n",
    "for i, date in enumerate(dates):\n",
    "    comb_json[date] = dataframe_collection[date].to_json(orient='index')\n",
    "    comb_json[date] = json.loads(comb_json[date])\n",
    "\n",
    "comb_json['minimum'] = minimums.to_json(orient='index')\n",
    "comb_json['minimum'] = json.loads(comb_json['minimum'])\n",
    "comb_json['maximum'] = maximums.to_json(orient='index')\n",
    "comb_json['maximum'] = json.loads(comb_json['maximum'])\n",
    "    \n",
    "with open('../data/week_mean_normalized.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(comb_json, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating weekly top songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": ".DS_Store\nCyprus_2019-07-04.csv\nCyprus_2017-07-27.csv\nCyprus_2019-12-19.csv\nCyprus_2019-02-21.csv\nCyprus_2017-12-07.csv\nCyprus_2017-02-02.csv\nCyprus_2017-02-16.csv\nCyprus_2018-08-23.csv\nCyprus_2019-07-11.csv\nCyprus_2018-08-09.csv\nCyprus_2018-01-11.csv\nCyprus_2017-09-21.csv\nCyprus_2019-12-26.csv\nCyprus_2019-05-02.csv\nCyprus_2019-05-16.csv\nCyprus_2018-03-15.csv\nCyprus_2018-03-01.csv\nCyprus_2018-03-29.csv\nCyprus_2018-11-01.csv\nCyprus_2018-11-15.csv\nCyprus_2018-11-29.csv\nCyprus_2018-01-04.csv\nCyprus_2017-10-05.csv\nCyprus_2018-08-30.csv\nCyprus_2018-06-21.csv\nCyprus_2020-01-16.csv\nCyprus_2020-01-02.csv\nCyprus_2017-12-28.csv\nCyprus_2017-12-14.csv\nCyprus_2018-04-19.csv\nCyprus_2017-07-20.csv\nCyprus_2019-09-12.csv\nCyprus_2017-10-12.csv\nCyprus_2019-10-31.csv\nCyprus_2018-04-26.csv\nCyprus_2019-10-24.csv\nCyprus_2019-09-05.csv\nCyprus_2018-02-08.csv\nCyprus_2019-08-22.csv\nCyprus_2019-06-27.csv\nCyprus_2017-01-19.csv\nCyprus_2018-07-05.csv\nCyprus_2017-11-09.csv\nCyprus_2017-03-09.csv\nCyprus_2017-03-23.csv\nCyprus_2019-03-14.csv\nCyprus_2019-03-28.csv\nCyprus_2017-11-23.csv\nCyprus_2017-01-26.csv\nCyprus_2019-11-14.csv\nCyprus_2019-11-28.csv\nCyprus_2017-08-03.csv\nCyprus_2017-08-17.csv\nCyprus_2018-07-12.csv\nCyprus_2019-08-08.csv\nCyprus_2019-01-10.csv\nCyprus_2018-05-17.csv\nCyprus_2018-05-03.csv\nCyprus_2018-02-22.csv\nCyprus_2018-12-27.csv\nCyprus_2017-04-13.csv\nCyprus_2019-04-18.csv\nCyprus_2018-09-13.csv\nCyprus_2018-09-06.csv\nCyprus_2019-06-20.csv\nCyprus_2019-04-25.csv\nCyprus_2017-04-06.csv\nCyprus_2018-12-20.csv\nCyprus_2018-05-10.csv\nCyprus_2019-01-17.csv\nCyprus_2019-01-03.csv\nCyprus_2017-06-29.csv\nCyprus_2017-08-10.csv\nCyprus_2017-06-15.csv\nCyprus_2018-10-25.csv\nCyprus_2019-11-07.csv\nCyprus_2018-10-18.csv\nCyprus_2017-11-30.csv\nCyprus_2019-03-07.csv\nCyprus_2017-03-30.csv\nCyprus_2017-04-20.csv\nCyprus_2018-02-01.csv\nCyprus_2018-02-15.csv\nCyprus_2018-09-20.csv\nCyprus_2018-07-19.csv\nCyprus_2019-06-06.csv\nCyprus_2017-01-05.csv\nCyprus_2019-06-13.csv\nCyprus_2017-03-16.csv\nCyprus_2017-03-02.csv\nCyprus_2018-12-13.csv\nCyprus_2019-03-21.csv\nCyprus_2017-11-02.csv\nCyprus_2017-11-16.csv\nCyprus_2019-01-24.csv\nCyprus_2018-07-26.csv\nCyprus_2019-11-21.csv\nCyprus_2017-01-12.csv\nCyprus_2019-08-29.csv\nCyprus_2019-01-31.csv\nCyprus_2019-08-15.csv\nCyprus_2019-08-01.csv\nCyprus_2018-12-06.csv\nCyprus_2019-04-11.csv\nCyprus_2017-06-22.csv\nCyprus_2018-09-27.csv\nCyprus_2019-04-04.csv\nCyprus_2017-04-27.csv\nCyprus_2018-05-31.csv\nCyprus_2017-06-08.csv\nCyprus_2017-08-31.csv\nCyprus_2018-10-04.csv\nCyprus_2018-10-11.csv\nCyprus_2017-08-24.csv\nCyprus_2018-05-24.csv\nCyprus_2019-07-25.csv\nCyprus_2017-07-06.csv\nCyprus_2018-11-22.csv\nCyprus_2018-03-22.csv\nCyprus_2019-02-14.csv\nCyprus_2019-05-09.csv\nCyprus_2019-02-28.csv\nCyprus_2019-12-05.csv\nCyprus_2017-02-23.csv\nCyprus_2017-07-13.csv\nCyprus_2018-08-02.csv\nCyprus_2019-07-18.csv\nCyprus_2018-06-07.csv\nCyprus_2018-01-18.csv\nCyprus_2017-09-14.csv\nCyprus_2017-09-28.csv\nCyprus_2017-02-09.csv\nCyprus_2019-05-23.csv\nCyprus_2018-03-08.csv\nCyprus_2019-12-12.csv\nCyprus_2019-10-17.csv\nCyprus_2019-10-03.csv\nCyprus_2018-11-08.csv\nCyprus_2018-01-25.csv\nCyprus_2018-06-28.csv\nCyprus_2019-09-26.csv\nCyprus_2018-06-14.csv\nCyprus_2017-05-11.csv\nCyprus_2020-01-23.csv\nCyprus_2017-12-21.csv\nCyprus_2019-02-07.csv\nCyprus_2018-04-05.csv\nCyprus_2017-05-04.csv\nCyprus_2017-10-19.csv\nCyprus_2019-09-19.csv\nCyprus_2019-10-10.csv\nCyprus_2018-04-12.csv\nCyprus_2019-05-30.csv\nCyprus_2020-01-09.csv\nCyprus_2017-09-07.csv\nCyprus_2017-10-26.csv\n.DS_Store\n"
    }
   ],
   "source": [
    "songs_norm = pd.read_csv(song_masterlist_norm)\n",
    "\n",
    "dataframe_collection = {}\n",
    "\n",
    "for date in dates:\n",
    "    dataframe_collection[date] = {}\n",
    "    for CC in CCs:\n",
    "        dataframe_collection[date][CC] = pd.DataFrame()\n",
    "\n",
    "for directory in os.listdir(base_dir):\n",
    "    path = base_dir + directory + '/'\n",
    "    try:\n",
    "        for filename in os.listdir(path):\n",
    "            try:\n",
    "                current_week = filename.replace('.','_').split('_')[1]\n",
    "                week_df = pd.read_csv(path + filename)\n",
    "\n",
    "                try:\n",
    "                    CC = pc.country_name_to_country_alpha3(directory, cn_name_format=\"default\")\n",
    "                except:\n",
    "                    CC = \"GLO\"\n",
    "                top_songs = songs_norm.iloc[week_df[\"Song_Index\"]]\n",
    "                top_songs = top_songs.reset_index(drop=True).head(20).dropna()\n",
    "                dataframe_collection[current_week][CC] = dataframe_collection[current_week][CC].append(top_songs)\n",
    "            except:\n",
    "                print(filename)\n",
    "    except:\n",
    "        print(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_json = {}\n",
    "for date in dates:\n",
    "    comb_json[date] = {}\n",
    "    for CC in CCs:\n",
    "        comb_json[date][CC] = {}\n",
    "\n",
    "for i, date in enumerate(dates):\n",
    "    for j, CC in enumerate(CCs):\n",
    "        comb_json[date][CC] = dataframe_collection[date][CC].to_json(orient='index')\n",
    "        comb_json[date][CC] = json.loads(comb_json[date][CC])\n",
    "    \n",
    "with open('../data/week_countries_songs_normalized.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(comb_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python37564bit822f958ef1a6469287a660318459b413"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}